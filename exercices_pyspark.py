# -*- coding: utf-8 -*-
"""exercices_pyspark.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VIz_v6-3vn-CZSQj9ACfp6GGtq6z8bke
"""

!pip install pyspark

from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Test PySpark").getOrCreate()
print("PySpark version:", spark.version)

data = """Date,Produit,Quantité,Prix_unitaire
2024-01-01,Ordinateur,2,800
2024-01-01,Clavier,5,20
2024-01-02,Souris,10,15
2024-01-02,Ordinateur,1,800
2024-01-03,Clavier,3,20
"""

with open("ventes.csv", "w") as file:
    file.write(data)

from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Analyse des ventes").getOrCreate()
ventes_df = spark.read.csv("ventes.csv", header=True, inferSchema=True)
ventes_df.show()

from pyspark.sql.functions import col

ventes_df = ventes_df.withColumn("Chiffre_d_affaires", col("Quantité") * col("Prix_unitaire"))
ventes_df.show()

total_ca = ventes_df.groupBy().sum("Chiffre_d_affaires").collect()[0][0]
print(f"Chiffre d’affaires total : {total_ca} €")

produit_plus_vendu = ventes_df.groupBy("Produit").sum("Quantité").orderBy("sum(Quantité)", ascending=False).first()
print(f"Produit le plus vendu : {produit_plus_vendu['Produit']} ({produit_plus_vendu['sum(Quantité)']} unités)")

import json

data = [
    {"id": 1, "nom": "Alice", "âge": 25, "ville": "Paris"},
    {"id": 2, "nom": "Bob", "âge": 30, "ville": "Lyon"},
    {"id": 3, "nom": "Claire", "âge": 35, "ville": "Paris"},
    {"id": 4, "nom": "David", "âge": 40, "ville": "Marseille"},
    {"id": 5, "nom": "Emma", "âge": 22, "ville": "Lyon"}
]

with open("utilisateurs.json", "w") as file:
    json.dump(data, file)

utilisateurs_df = spark.read.json("utilisateurs.json")
utilisateurs_df.show()

from pyspark.sql.functions import avg

age_moyen = utilisateurs_df.groupBy().avg("âge").collect()[0][0]
print(f"Âge moyen : {age_moyen:.1f} ans")

utilisateurs_par_ville = utilisateurs_df.groupBy("ville").count()
utilisateurs_par_ville.show()

plus_jeune = utilisateurs_df.orderBy("âge").first()
print(f"Plus jeune utilisateur : {plus_jeune['nom']} ({plus_jeune['âge']} ans)")

data = """Nom,Âge,Ville,Revenu
Alice,25,Paris,50000
Bob,,Lyon,40000
Claire,35,Marseille,35000
David,40,,45000
Emma,22,Lyon,
"""

with open("clients.csv", "w") as file:
    file.write(data)

clients_df = spark.read.csv("clients.csv", header=True, inferSchema=True)
clients_df.show()

from pyspark.sql.functions import mean

age_moyen = clients_df.select(mean("Âge")).collect()[0][0]
clients_df = clients_df.fillna({"Âge": age_moyen, "Ville": "Inconnue"})

clients_df = clients_df.na.drop(subset=["Revenu"])
clients_df.show()

data = """Produit,Catégorie,Prix
Ordinateur,Électronique,800
Clavier,Électronique,20
Souris,Électronique,15
Table,Bureau,150
Chaise,Bureau,80
Imprimante,Électronique,120
"""

with open("produits.csv", "w") as file:
    file.write(data)

produits_df = spark.read.csv("produits.csv", header=True, inferSchema=True)
produits_df.show()

produits_plus_chers = produits_df.orderBy("Prix", ascending=False).limit(3)
produits_plus_chers.show()

data = """Client,Date,Montant
Alice,2024-01-01,150
Bob,2024-01-02,200
Alice,2024-01-03,100
Emma,2024-01-04,300
David,2024-01-05,250
Emma,2024-01-06,50
"""

with open("transactions.csv", "w") as file:
    file.write(data)

from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Analyse des transactions").getOrCreate()
transactions_df = spark.read.csv("transactions.csv", header=True, inferSchema=True)
transactions_df.show()

from pyspark.sql.functions import sum

depenses_totales = transactions_df.groupBy("Client").agg(sum("Montant").alias("Dépenses_totales"))
depenses_totales.show()

client_max = depenses_totales.orderBy("Dépenses_totales", ascending=False)
client_max.show()

top_client = client_max.first()
print(f"Client ayant dépensé le plus : {top_client['Client']} ({top_client['Dépenses_totales']} €)")

from pyspark.sql.functions import avg, sum

stats_categorie = produits_df.groupBy("Catégorie").agg(
    avg("Prix").alias("Prix_moyen"),
    sum("Prix").alias("Prix_total")
)
stats_categorie.show()

!git clone https://github.com/MohammedBabaEpisen/TP_pyspark.git

!git config --global user.name "MohammedBabaEpisen"
!git config --global user.email "mohammed.baba@etu.u-pec.fr"

with open("script.py", "w") as f:
    f.write("print('Bonjour depuis Google Colab')")